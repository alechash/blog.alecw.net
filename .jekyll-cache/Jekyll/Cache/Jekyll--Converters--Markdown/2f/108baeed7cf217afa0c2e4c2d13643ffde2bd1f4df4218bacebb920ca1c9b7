I"Ç<p>As we all know, open-source and community-driven projects are starting to gain traction around the internet. The decentralized idea of the internet is also starting to happen and crypto prices are at an all time high. So why doesnâ€™t a decentralized or community driven search engine exist yet?</p>

<h1 id="the-idea">The Idea</h1>

<p>The idea is a search engine whoâ€™s results were come up with by the community. Blockchain is the idea of multiple computers coming together as one decentralized computer and solving math problems together to earn digital coin.</p>

<p>So, what if instead of solving math problems, they were crawling the web. And there was a central server where this information went to and was used in web search.</p>

<p>How would a crawler get paid? Well, just like blockchain, through cryptocurrency. For example, SearchCoin.</p>

<h1 id="building-it">Building It</h1>

<p>You would need to build these items for this to work Software to run on peoples computers</p>

<ul>
  <li>A centralized server to accept data and send out coins</li>
  <li>A web interface for people to search on</li>
  <li>Ad network to generate revenue on the web interface</li>
  <li>A new coin to distribute to contributors</li>
</ul>

<h1 id="web-server">Web Server</h1>

<p>First, youâ€™d need a server. This server should just be a simple web server like a Nodejs web server that is connected to a database. This web server will also need a couple APIs that the crawling software will communicate with.</p>

<p>Ideally you would have a database of URLs to be crawled. Either user-submitted or find by crawlers that the crawler could not get to. Crawling Software</p>

<p>You could really do this with Electron. This software should communicate with the web server and receive URLs to crawl. It would then crawl these URLs and get information like description, title, and other meta stuff. It would then send this to the web server which would put it in a database. The server would verify this information and if verified, give the crawler some coin.</p>

<p>The web server would then check this URL as crawled and would only re-crawl it again if prompted by a crawler or a user of the web interface.</p>

<h1 id="web-interface">Web Interface</h1>

<p>This could just be as simple as an HTML input field that went to /search?q={query}. It would then show results. But, you could also have an input box to request a site to be crawled. It would then queue this site.</p>

<h1 id="search-coin">Search Coin</h1>

<p>This would just be a crypto coin or token that would be sent to people for crawling sites.</p>

<h1 id="final-thoughts">Final Thoughts</h1>

<p>As you can probably tell, this idea is not completely fleshed out. Especially in the corners of the actual coin and how the server would verify this information.</p>

<h1 id="why-it-doesnt-exist-now">Why It Doesnâ€™t Exist Now</h1>

<p>There are many reasons, including the fact that there are already a lot of search engines that people could choose from. Another reason is expenses. Or lack of community support.</p>

<p>There are many reasons, including the fact that there are already a lot of search engines that people could choose from. Another reason is expenses. Or lack of community support.</p>
:ET